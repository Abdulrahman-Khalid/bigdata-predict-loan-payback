{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\n"
     ]
    }
   ],
   "source": [
    "# Spark Session, Pipeline, Functions, and Metrics\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, StandardScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Keras / Deep Learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import optimizers, regularizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Elephas for Deep Learning on Spark\n",
    "from elephas.ml_model import ElephasEstimator\n",
    "\n",
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "from pyspark.sql.functions import col, create_map, lit\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "conf = SparkConf().setAppName('Predict Loan Payback').setMaster('local[6]') # 6 cores\n",
    "sc = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[6]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Predict Loan Payback</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[6] appName=Predict Loan Payback>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sc.stop()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data to Spark Dataframe\n",
    "df = sql_context.read.csv(\"./data/accepted_2007_to_2018Q4.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- member_id: string (nullable = true)\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- funded_amnt: double (nullable = true)\n",
      " |-- funded_amnt_inv: double (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- installment: double (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- emp_title: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: string (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- issue_d: string (nullable = true)\n",
      " |-- loan_status: string (nullable = true)\n",
      " |-- pymnt_plan: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      " |-- addr_state: string (nullable = true)\n",
      " |-- dti: string (nullable = true)\n",
      " |-- delinq_2yrs: string (nullable = true)\n",
      " |-- earliest_cr_line: string (nullable = true)\n",
      " |-- fico_range_low: string (nullable = true)\n",
      " |-- fico_range_high: string (nullable = true)\n",
      " |-- inq_last_6mths: string (nullable = true)\n",
      " |-- mths_since_last_delinq: string (nullable = true)\n",
      " |-- mths_since_last_record: string (nullable = true)\n",
      " |-- open_acc: string (nullable = true)\n",
      " |-- pub_rec: string (nullable = true)\n",
      " |-- revol_bal: string (nullable = true)\n",
      " |-- revol_util: string (nullable = true)\n",
      " |-- total_acc: string (nullable = true)\n",
      " |-- initial_list_status: string (nullable = true)\n",
      " |-- out_prncp: string (nullable = true)\n",
      " |-- out_prncp_inv: string (nullable = true)\n",
      " |-- total_pymnt: string (nullable = true)\n",
      " |-- total_pymnt_inv: string (nullable = true)\n",
      " |-- total_rec_prncp: string (nullable = true)\n",
      " |-- total_rec_int: string (nullable = true)\n",
      " |-- total_rec_late_fee: string (nullable = true)\n",
      " |-- recoveries: string (nullable = true)\n",
      " |-- collection_recovery_fee: string (nullable = true)\n",
      " |-- last_pymnt_d: string (nullable = true)\n",
      " |-- last_pymnt_amnt: string (nullable = true)\n",
      " |-- next_pymnt_d: string (nullable = true)\n",
      " |-- last_credit_pull_d: string (nullable = true)\n",
      " |-- last_fico_range_high: string (nullable = true)\n",
      " |-- last_fico_range_low: string (nullable = true)\n",
      " |-- collections_12_mths_ex_med: string (nullable = true)\n",
      " |-- mths_since_last_major_derog: string (nullable = true)\n",
      " |-- policy_code: string (nullable = true)\n",
      " |-- application_type: string (nullable = true)\n",
      " |-- annual_inc_joint: string (nullable = true)\n",
      " |-- dti_joint: string (nullable = true)\n",
      " |-- verification_status_joint: string (nullable = true)\n",
      " |-- acc_now_delinq: string (nullable = true)\n",
      " |-- tot_coll_amt: string (nullable = true)\n",
      " |-- tot_cur_bal: string (nullable = true)\n",
      " |-- open_acc_6m: string (nullable = true)\n",
      " |-- open_act_il: string (nullable = true)\n",
      " |-- open_il_12m: string (nullable = true)\n",
      " |-- open_il_24m: string (nullable = true)\n",
      " |-- mths_since_rcnt_il: string (nullable = true)\n",
      " |-- total_bal_il: string (nullable = true)\n",
      " |-- il_util: string (nullable = true)\n",
      " |-- open_rv_12m: string (nullable = true)\n",
      " |-- open_rv_24m: string (nullable = true)\n",
      " |-- max_bal_bc: string (nullable = true)\n",
      " |-- all_util: string (nullable = true)\n",
      " |-- total_rev_hi_lim: string (nullable = true)\n",
      " |-- inq_fi: string (nullable = true)\n",
      " |-- total_cu_tl: string (nullable = true)\n",
      " |-- inq_last_12m: double (nullable = true)\n",
      " |-- acc_open_past_24mths: double (nullable = true)\n",
      " |-- avg_cur_bal: string (nullable = true)\n",
      " |-- bc_open_to_buy: double (nullable = true)\n",
      " |-- bc_util: string (nullable = true)\n",
      " |-- chargeoff_within_12_mths: double (nullable = true)\n",
      " |-- delinq_amnt: double (nullable = true)\n",
      " |-- mo_sin_old_il_acct: double (nullable = true)\n",
      " |-- mo_sin_old_rev_tl_op: double (nullable = true)\n",
      " |-- mo_sin_rcnt_rev_tl_op: double (nullable = true)\n",
      " |-- mo_sin_rcnt_tl: double (nullable = true)\n",
      " |-- mort_acc: double (nullable = true)\n",
      " |-- mths_since_recent_bc: double (nullable = true)\n",
      " |-- mths_since_recent_bc_dlq: double (nullable = true)\n",
      " |-- mths_since_recent_inq: double (nullable = true)\n",
      " |-- mths_since_recent_revol_delinq: double (nullable = true)\n",
      " |-- num_accts_ever_120_pd: double (nullable = true)\n",
      " |-- num_actv_bc_tl: double (nullable = true)\n",
      " |-- num_actv_rev_tl: double (nullable = true)\n",
      " |-- num_bc_sats: double (nullable = true)\n",
      " |-- num_bc_tl: double (nullable = true)\n",
      " |-- num_il_tl: double (nullable = true)\n",
      " |-- num_op_rev_tl: double (nullable = true)\n",
      " |-- num_rev_accts: double (nullable = true)\n",
      " |-- num_rev_tl_bal_gt_0: double (nullable = true)\n",
      " |-- num_sats: double (nullable = true)\n",
      " |-- num_tl_120dpd_2m: double (nullable = true)\n",
      " |-- num_tl_30dpd: double (nullable = true)\n",
      " |-- num_tl_90g_dpd_24m: double (nullable = true)\n",
      " |-- num_tl_op_past_12m: double (nullable = true)\n",
      " |-- pct_tl_nvr_dlq: double (nullable = true)\n",
      " |-- percent_bc_gt_75: double (nullable = true)\n",
      " |-- pub_rec_bankruptcies: double (nullable = true)\n",
      " |-- tax_liens: double (nullable = true)\n",
      " |-- tot_hi_cred_lim: double (nullable = true)\n",
      " |-- total_bal_ex_mort: double (nullable = true)\n",
      " |-- total_bc_limit: double (nullable = true)\n",
      " |-- total_il_high_credit_limit: double (nullable = true)\n",
      " |-- revol_bal_joint: double (nullable = true)\n",
      " |-- sec_app_fico_range_low: double (nullable = true)\n",
      " |-- sec_app_fico_range_high: double (nullable = true)\n",
      " |-- sec_app_earliest_cr_line: string (nullable = true)\n",
      " |-- sec_app_inq_last_6mths: double (nullable = true)\n",
      " |-- sec_app_mort_acc: double (nullable = true)\n",
      " |-- sec_app_open_acc: double (nullable = true)\n",
      " |-- sec_app_revol_util: double (nullable = true)\n",
      " |-- sec_app_open_act_il: double (nullable = true)\n",
      " |-- sec_app_num_rev_accts: double (nullable = true)\n",
      " |-- sec_app_chargeoff_within_12_mths: double (nullable = true)\n",
      " |-- sec_app_collections_12_mths_ex_med: double (nullable = true)\n",
      " |-- sec_app_mths_since_last_major_derog: double (nullable = true)\n",
      " |-- hardship_flag: string (nullable = true)\n",
      " |-- hardship_type: string (nullable = true)\n",
      " |-- hardship_reason: string (nullable = true)\n",
      " |-- hardship_status: string (nullable = true)\n",
      " |-- deferral_term: string (nullable = true)\n",
      " |-- hardship_amount: string (nullable = true)\n",
      " |-- hardship_start_date: string (nullable = true)\n",
      " |-- hardship_end_date: string (nullable = true)\n",
      " |-- payment_plan_start_date: string (nullable = true)\n",
      " |-- hardship_length: string (nullable = true)\n",
      " |-- hardship_dpd: string (nullable = true)\n",
      " |-- hardship_loan_status: string (nullable = true)\n",
      " |-- orig_projected_additional_accrued_interest: string (nullable = true)\n",
      " |-- hardship_payoff_balance_amount: string (nullable = true)\n",
      " |-- hardship_last_payment_amount: string (nullable = true)\n",
      " |-- disbursement_method: string (nullable = true)\n",
      " |-- debt_settlement_flag: string (nullable = true)\n",
      " |-- debt_settlement_flag_date: string (nullable = true)\n",
      " |-- settlement_status: string (nullable = true)\n",
      " |-- settlement_date: string (nullable = true)\n",
      " |-- settlement_amount: string (nullable = true)\n",
      " |-- settlement_percentage: string (nullable = true)\n",
      " |-- settlement_term: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68407277</td>\n",
       "      <td>None</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.99</td>\n",
       "      <td>123.03</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68355089</td>\n",
       "      <td>None</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>11.99</td>\n",
       "      <td>820.28</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68341763</td>\n",
       "      <td>None</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>10.78</td>\n",
       "      <td>432.66</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66310712</td>\n",
       "      <td>None</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>14.85</td>\n",
       "      <td>829.90</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68476807</td>\n",
       "      <td>None</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>22.45</td>\n",
       "      <td>289.91</td>\n",
       "      <td>F</td>\n",
       "      <td>F1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  68407277      None     3600.0       3600.0           3600.0   36 months   \n",
       "1  68355089      None    24700.0      24700.0          24700.0   36 months   \n",
       "2  68341763      None    20000.0      20000.0          20000.0   60 months   \n",
       "3  66310712      None    35000.0      35000.0          35000.0   60 months   \n",
       "4  68476807      None    10400.0      10400.0          10400.0   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
       "0     13.99       123.03     C        C4  ...                           None   \n",
       "1     11.99       820.28     C        C1  ...                           None   \n",
       "2     10.78       432.66     B        B4  ...                           None   \n",
       "3     14.85       829.90     C        C5  ...                           None   \n",
       "4     22.45       289.91     F        F1  ...                           None   \n",
       "\n",
       "  hardship_last_payment_amount disbursement_method debt_settlement_flag  \\\n",
       "0                         None                Cash                    N   \n",
       "1                         None                Cash                    N   \n",
       "2                         None                Cash                    N   \n",
       "3                         None                Cash                    N   \n",
       "4                         None                Cash                    N   \n",
       "\n",
       "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
       "0                      None              None            None   \n",
       "1                      None              None            None   \n",
       "2                      None              None            None   \n",
       "3                      None              None            None   \n",
       "4                      None              None            None   \n",
       "\n",
       "  settlement_amount settlement_percentage settlement_term  \n",
       "0              None                  None            None  \n",
       "1              None                  None            None  \n",
       "2              None                  None            None  \n",
       "3              None                  None            None  \n",
       "4              None                  None            None  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>1076751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Default</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In Grace Period</td>\n",
       "      <td>8436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does not meet the credit policy. Status:Fully ...</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>268558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oct-2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Late (31-120 days)</td>\n",
       "      <td>21467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Current</td>\n",
       "      <td>878317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Does not meet the credit policy. Status:Charge...</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Late (16-30 days)</td>\n",
       "      <td>4349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          loan_status    count\n",
       "0                                          Fully Paid  1076751\n",
       "1                                             Default       40\n",
       "2                                                None       33\n",
       "3                                     In Grace Period     8436\n",
       "4   Does not meet the credit policy. Status:Fully ...     1988\n",
       "5                                         Charged Off   268558\n",
       "6                                            Oct-2015        1\n",
       "7                                  Late (31-120 days)    21467\n",
       "8                                             Current   878317\n",
       "9   Does not meet the credit policy. Status:Charge...      761\n",
       "10                                  Late (16-30 days)     4349"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"loan_status\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter('loan_status in (\"Fully Paid\", \"Charged Off\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>1076751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>268558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_status    count\n",
       "0   Fully Paid  1076751\n",
       "1  Charged Off   268558"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"loan_status\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id', 'pymnt_plan', 'hardship_flag', 'out_prncp', 'out_prncp_inv', 'policy_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_df_shape(df):\n",
    "    return df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1345309, 145)\n"
     ]
    }
   ],
   "source": [
    "print(spark_df_shape(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's drop these columns, as it will not contribute to our goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1345309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85785</td>\n",
       "      <td>...</td>\n",
       "      <td>1339554</td>\n",
       "      <td>1339554</td>\n",
       "      <td>226</td>\n",
       "      <td>171</td>\n",
       "      <td>1311942</td>\n",
       "      <td>1311957</td>\n",
       "      <td>1311977</td>\n",
       "      <td>1311998</td>\n",
       "      <td>1312012</td>\n",
       "      <td>1312016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   member_id  loan_amnt  funded_amnt  funded_amnt_inv  term  int_rate  \\\n",
       "0    1345309          0            0                0     0         0   \n",
       "\n",
       "   installment  grade  sub_grade  emp_title  ...  \\\n",
       "0            0      0          0      85785  ...   \n",
       "\n",
       "   hardship_payoff_balance_amount  hardship_last_payment_amount  \\\n",
       "0                         1339554                       1339554   \n",
       "\n",
       "   disbursement_method  debt_settlement_flag  debt_settlement_flag_date  \\\n",
       "0                  226                   171                    1311942   \n",
       "\n",
       "   settlement_status  settlement_date  settlement_amount  \\\n",
       "0            1311957          1311977            1311998   \n",
       "\n",
       "   settlement_percentage  settlement_term  \n",
       "0                1312012          1312016  \n",
       "\n",
       "[1 rows x 145 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "member_id                                     1345309\n",
       "next_pymnt_d                                  1345086\n",
       "orig_projected_additional_accrued_interest    1341548\n",
       "hardship_last_payment_amount                  1339554\n",
       "hardship_payoff_balance_amount                1339554\n",
       "hardship_dpd                                  1339550\n",
       "hardship_loan_status                          1339548\n",
       "hardship_start_date                           1339547\n",
       "hardship_end_date                             1339546\n",
       "hardship_length                               1339545\n",
       "payment_plan_start_date                       1339543\n",
       "hardship_amount                               1339540\n",
       "deferral_term                                 1339532\n",
       "hardship_status                               1339521\n",
       "hardship_reason                               1339513\n",
       "hardship_type                                 1339504\n",
       "sec_app_mths_since_last_major_derog           1338662\n",
       "sec_app_revol_util                            1327004\n",
       "sec_app_num_rev_accts                         1326678\n",
       "sec_app_open_act_il                           1326677\n",
       "sec_app_chargeoff_within_12_mths              1326673\n",
       "sec_app_collections_12_mths_ex_med            1326672\n",
       "sec_app_open_acc                              1326670\n",
       "sec_app_mort_acc                              1326668\n",
       "sec_app_inq_last_6mths                        1326665\n",
       "sec_app_fico_range_low                        1326662\n",
       "revol_bal_joint                               1326658\n",
       "sec_app_earliest_cr_line                      1326657\n",
       "sec_app_fico_range_high                       1326657\n",
       "verification_status_joint                     1319597\n",
       "dti_joint                                     1319367\n",
       "annual_inc_joint                              1319330\n",
       "settlement_term                               1312016\n",
       "settlement_percentage                         1312012\n",
       "settlement_amount                             1311998\n",
       "settlement_date                               1311977\n",
       "settlement_status                             1311957\n",
       "debt_settlement_flag_date                     1311942\n",
       "desc                                          1221777\n",
       "mths_since_last_record                        1116581\n",
       "mths_since_recent_bc_dlq                      1026267\n",
       "mths_since_last_major_derog                    991349\n",
       "mths_since_recent_revol_delinq                 895331\n",
       "il_util                                        880270\n",
       "mths_since_rcnt_il                             821897\n",
       "all_util                                       807758\n",
       "inq_last_12m                                   807711\n",
       "inq_fi                                         807707\n",
       "total_cu_tl                                    807703\n",
       "max_bal_bc                                     807700\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop.sum().sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open_rv_12m                   807699\n",
       "open_rv_24m                   807693\n",
       "total_bal_il                  807685\n",
       "open_il_24m                   807678\n",
       "open_il_12m                   807673\n",
       "open_act_il                   807645\n",
       "open_acc_6m                   807631\n",
       "mths_since_last_delinq        678599\n",
       "mths_since_recent_inq         174049\n",
       "num_tl_120dpd_2m              117400\n",
       "mo_sin_old_il_acct            105485\n",
       "emp_title                      85785\n",
       "emp_length                     78511\n",
       "pct_tl_nvr_dlq                 67681\n",
       "avg_cur_bal                    67546\n",
       "num_tl_30dpd                   67527\n",
       "num_bc_tl                      67526\n",
       "num_rev_accts                  67526\n",
       "num_tl_op_past_12m             67525\n",
       "num_actv_rev_tl                67525\n",
       "num_tl_90g_dpd_24m             67525\n",
       "num_rev_tl_bal_gt_0            67525\n",
       "total_rev_hi_lim               67522\n",
       "num_il_tl                      67521\n",
       "num_op_rev_tl                  67520\n",
       "num_actv_bc_tl                 67518\n",
       "num_accts_ever_120_pd          67516\n",
       "total_il_high_credit_limit     67493\n",
       "mo_sin_rcnt_tl                 67493\n",
       "mo_sin_rcnt_rev_tl_op          67474\n",
       "mo_sin_old_rev_tl_op           67454\n",
       "tot_hi_cred_lim                67440\n",
       "tot_cur_bal                    67433\n",
       "tot_coll_amt                   67410\n",
       "bc_util                        61912\n",
       "percent_bc_gt_75               61555\n",
       "bc_open_to_buy                 61142\n",
       "mths_since_recent_bc           60204\n",
       "num_sats                       55839\n",
       "num_bc_sats                    55839\n",
       "acc_open_past_24mths           47278\n",
       "mort_acc                       47260\n",
       "total_bc_limit                 47228\n",
       "total_bal_ex_mort              47209\n",
       "title                          16660\n",
       "last_pymnt_d                    2320\n",
       "pub_rec_bankruptcies             911\n",
       "revol_util                       886\n",
       "dti                              375\n",
       "chargeoff_within_12_mths         281\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop.sum().sort_values(ascending=False)[50:].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 95 columns has lots of nulls so I will drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = list(to_drop.sum().sort_values(ascending=False).head(95).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['member_id', 'next_pymnt_d', 'orig_projected_additional_accrued_interest', 'hardship_last_payment_amount', 'hardship_payoff_balance_amount', 'hardship_dpd', 'hardship_loan_status', 'hardship_start_date', 'hardship_end_date', 'hardship_length', 'payment_plan_start_date', 'hardship_amount', 'deferral_term', 'hardship_status', 'hardship_reason', 'hardship_type', 'sec_app_mths_since_last_major_derog', 'sec_app_revol_util', 'sec_app_num_rev_accts', 'sec_app_open_act_il', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'sec_app_open_acc', 'sec_app_mort_acc', 'sec_app_inq_last_6mths', 'sec_app_fico_range_low', 'revol_bal_joint', 'sec_app_earliest_cr_line', 'sec_app_fico_range_high', 'verification_status_joint', 'dti_joint', 'annual_inc_joint', 'settlement_term', 'settlement_percentage', 'settlement_amount', 'settlement_date', 'settlement_status', 'debt_settlement_flag_date', 'desc', 'mths_since_last_record', 'mths_since_recent_bc_dlq', 'mths_since_last_major_derog', 'mths_since_recent_revol_delinq', 'il_util', 'mths_since_rcnt_il', 'all_util', 'inq_last_12m', 'inq_fi', 'total_cu_tl', 'max_bal_bc', 'open_rv_12m', 'open_rv_24m', 'total_bal_il', 'open_il_24m', 'open_il_12m', 'open_act_il', 'open_acc_6m', 'mths_since_last_delinq', 'mths_since_recent_inq', 'num_tl_120dpd_2m', 'mo_sin_old_il_acct', 'emp_title', 'emp_length', 'pct_tl_nvr_dlq', 'avg_cur_bal', 'num_tl_30dpd', 'num_bc_tl', 'num_rev_accts', 'num_tl_op_past_12m', 'num_actv_rev_tl', 'num_tl_90g_dpd_24m', 'num_rev_tl_bal_gt_0', 'total_rev_hi_lim', 'num_il_tl', 'num_op_rev_tl', 'num_actv_bc_tl', 'num_accts_ever_120_pd', 'total_il_high_credit_limit', 'mo_sin_rcnt_tl', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_old_rev_tl_op', 'tot_hi_cred_lim', 'tot_cur_bal', 'tot_coll_amt', 'bc_util', 'percent_bc_gt_75', 'bc_open_to_buy', 'mths_since_recent_bc', 'num_sats', 'num_bc_sats', 'acc_open_past_24mths', 'mort_acc', 'total_bc_limit', 'total_bal_ex_mort', 'title']\n"
     ]
    }
   ],
   "source": [
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1345309, 50)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340812, 50)\n"
     ]
    }
   ],
   "source": [
    "print(spark_df_shape(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['fico_range_low', 'funded_amnt_inv', 'funded_amnt', 'total_pymnt_inv', 'total_pymnt', 'installment', 'collection_recovery_fee', 'total_rec_prncp', 'last_fico_range_low']\n",
    "df = df.drop(*to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340812, 41)\n"
     ]
    }
   ],
   "source": [
    "print(spark_df_shape(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'Fully Paid': 1, 'Charged Off': 0}\n",
    "\n",
    "mapping_expr = create_map([lit(x) for x in chain(*mapping.items())])\n",
    "\n",
    "df = df.withColumn(\"loan_is_paid\", mapping_expr[col(\"loan_status\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_is_paid</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1074961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>265851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_is_paid    count\n",
       "0             1  1074961\n",
       "1             0   265851"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"loan_is_paid\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_terms = [x.term for x in df.select('term').distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 36 months', ' 60 months']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(distinct_terms, [36, 60]))\n",
    "mapping_expr = create_map([lit(x) for x in chain(*mapping.items())])\n",
    "df = df.withColumn(\"term_months\", mapping_expr[col(\"term\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|term_months|\n",
      "+-----------+\n",
      "|         60|\n",
      "|         36|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"term_months\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: string (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- issue_d: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      " |-- addr_state: string (nullable = true)\n",
      " |-- dti: string (nullable = true)\n",
      " |-- delinq_2yrs: string (nullable = true)\n",
      " |-- earliest_cr_line: string (nullable = true)\n",
      " |-- fico_range_high: string (nullable = true)\n",
      " |-- inq_last_6mths: string (nullable = true)\n",
      " |-- open_acc: string (nullable = true)\n",
      " |-- pub_rec: string (nullable = true)\n",
      " |-- revol_bal: string (nullable = true)\n",
      " |-- revol_util: string (nullable = true)\n",
      " |-- total_acc: string (nullable = true)\n",
      " |-- initial_list_status: string (nullable = true)\n",
      " |-- total_rec_int: string (nullable = true)\n",
      " |-- total_rec_late_fee: string (nullable = true)\n",
      " |-- recoveries: string (nullable = true)\n",
      " |-- last_pymnt_d: string (nullable = true)\n",
      " |-- last_pymnt_amnt: string (nullable = true)\n",
      " |-- last_credit_pull_d: string (nullable = true)\n",
      " |-- last_fico_range_high: string (nullable = true)\n",
      " |-- collections_12_mths_ex_med: string (nullable = true)\n",
      " |-- application_type: string (nullable = true)\n",
      " |-- acc_now_delinq: string (nullable = true)\n",
      " |-- chargeoff_within_12_mths: double (nullable = true)\n",
      " |-- delinq_amnt: double (nullable = true)\n",
      " |-- pub_rec_bankruptcies: double (nullable = true)\n",
      " |-- tax_liens: double (nullable = true)\n",
      " |-- disbursement_method: string (nullable = true)\n",
      " |-- debt_settlement_flag: string (nullable = true)\n",
      " |-- loan_is_paid: integer (nullable = true)\n",
      " |-- term_months: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OWN</td>\n",
       "      <td>144179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENT</td>\n",
       "      <td>532381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>663782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANY</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NONE</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  home_ownership   count\n",
       "0            OWN  144179\n",
       "1           RENT  532381\n",
       "2       MORTGAGE  663782\n",
       "3            ANY     283\n",
       "4          OTHER     142\n",
       "5           NONE      45"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('home_ownership').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('NONE', 'ANY', 'home_ownership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OWN</td>\n",
       "      <td>144179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENT</td>\n",
       "      <td>532381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>663782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANY</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  home_ownership   count\n",
       "0            OWN  144179\n",
       "1           RENT  532381\n",
       "2       MORTGAGE  663782\n",
       "3            ANY     328\n",
       "4          OTHER     142"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('home_ownership').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop=['grade', 'issue_d', 'url', 'last_pymnt_d', 'last_credit_pull_d', 'zip_code', 'addr_state', 'earliest_cr_line']\n",
    "df = df.drop(*to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: string (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- dti: string (nullable = true)\n",
      " |-- delinq_2yrs: string (nullable = true)\n",
      " |-- fico_range_high: string (nullable = true)\n",
      " |-- inq_last_6mths: string (nullable = true)\n",
      " |-- open_acc: string (nullable = true)\n",
      " |-- pub_rec: string (nullable = true)\n",
      " |-- revol_bal: string (nullable = true)\n",
      " |-- revol_util: string (nullable = true)\n",
      " |-- total_acc: string (nullable = true)\n",
      " |-- initial_list_status: string (nullable = true)\n",
      " |-- total_rec_int: string (nullable = true)\n",
      " |-- total_rec_late_fee: string (nullable = true)\n",
      " |-- recoveries: string (nullable = true)\n",
      " |-- last_pymnt_amnt: string (nullable = true)\n",
      " |-- last_fico_range_high: string (nullable = true)\n",
      " |-- collections_12_mths_ex_med: string (nullable = true)\n",
      " |-- application_type: string (nullable = true)\n",
      " |-- acc_now_delinq: string (nullable = true)\n",
      " |-- chargeoff_within_12_mths: double (nullable = true)\n",
      " |-- delinq_amnt: double (nullable = true)\n",
      " |-- pub_rec_bankruptcies: double (nullable = true)\n",
      " |-- tax_liens: double (nullable = true)\n",
      " |-- disbursement_method: string (nullable = true)\n",
      " |-- debt_settlement_flag: string (nullable = true)\n",
      " |-- loan_is_paid: integer (nullable = true)\n",
      " |-- term_months: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['annual_inc', 'dti', 'delinq_2yrs', 'fico_range_high', 'inq_last_6mths', \n",
    "        'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'total_rec_int', \n",
    "        'total_rec_late_fee', 'recoveries', 'last_pymnt_amnt', 'last_fico_range_high', \n",
    "        'collections_12_mths_ex_med', 'acc_now_delinq']\n",
    "for col_name in cols:\n",
    "    df = df.withColumn(col_name, col(col_name).cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- dti: float (nullable = true)\n",
      " |-- delinq_2yrs: float (nullable = true)\n",
      " |-- fico_range_high: float (nullable = true)\n",
      " |-- inq_last_6mths: float (nullable = true)\n",
      " |-- open_acc: float (nullable = true)\n",
      " |-- pub_rec: float (nullable = true)\n",
      " |-- revol_bal: float (nullable = true)\n",
      " |-- revol_util: float (nullable = true)\n",
      " |-- total_acc: float (nullable = true)\n",
      " |-- initial_list_status: string (nullable = true)\n",
      " |-- total_rec_int: float (nullable = true)\n",
      " |-- total_rec_late_fee: float (nullable = true)\n",
      " |-- recoveries: float (nullable = true)\n",
      " |-- last_pymnt_amnt: float (nullable = true)\n",
      " |-- last_fico_range_high: float (nullable = true)\n",
      " |-- collections_12_mths_ex_med: float (nullable = true)\n",
      " |-- application_type: string (nullable = true)\n",
      " |-- acc_now_delinq: float (nullable = true)\n",
      " |-- chargeoff_within_12_mths: double (nullable = true)\n",
      " |-- delinq_amnt: double (nullable = true)\n",
      " |-- pub_rec_bankruptcies: double (nullable = true)\n",
      " |-- tax_liens: double (nullable = true)\n",
      " |-- disbursement_method: string (nullable = true)\n",
      " |-- debt_settlement_flag: string (nullable = true)\n",
      " |-- loan_is_paid: integer (nullable = true)\n",
      " |-- term_months: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>...</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>loan_is_paid</th>\n",
       "      <th>term_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>13.99</td>\n",
       "      <td>C4</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>5.910000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24700.0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>C1</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>small_business</td>\n",
       "      <td>16.059999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>10.78</td>\n",
       "      <td>B4</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>10.780000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Joint App</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10400.0</td>\n",
       "      <td>22.45</td>\n",
       "      <td>F1</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>104433.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>25.370001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11950.0</td>\n",
       "      <td>13.44</td>\n",
       "      <td>C3</td>\n",
       "      <td>RENT</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate sub_grade home_ownership  annual_inc  \\\n",
       "0     3600.0     13.99        C4       MORTGAGE     55000.0   \n",
       "1    24700.0     11.99        C1       MORTGAGE     65000.0   \n",
       "2    20000.0     10.78        B4       MORTGAGE     63000.0   \n",
       "3    10400.0     22.45        F1       MORTGAGE    104433.0   \n",
       "4    11950.0     13.44        C3           RENT     34000.0   \n",
       "\n",
       "  verification_status             purpose        dti  delinq_2yrs  \\\n",
       "0        Not Verified  debt_consolidation   5.910000          0.0   \n",
       "1        Not Verified      small_business  16.059999          1.0   \n",
       "2        Not Verified    home_improvement  10.780000          0.0   \n",
       "3     Source Verified      major_purchase  25.370001          1.0   \n",
       "4     Source Verified  debt_consolidation  10.200000          0.0   \n",
       "\n",
       "   fico_range_high  ...  application_type  acc_now_delinq  \\\n",
       "0            679.0  ...        Individual             0.0   \n",
       "1            719.0  ...        Individual             0.0   \n",
       "2            699.0  ...         Joint App             0.0   \n",
       "3            699.0  ...        Individual             0.0   \n",
       "4            694.0  ...        Individual             0.0   \n",
       "\n",
       "   chargeoff_within_12_mths  delinq_amnt  pub_rec_bankruptcies  tax_liens  \\\n",
       "0                       0.0          0.0                   0.0        0.0   \n",
       "1                       0.0          0.0                   0.0        0.0   \n",
       "2                       0.0          0.0                   0.0        0.0   \n",
       "3                       0.0          0.0                   0.0        0.0   \n",
       "4                       0.0          0.0                   0.0        0.0   \n",
       "\n",
       "  disbursement_method  debt_settlement_flag  loan_is_paid  term_months  \n",
       "0                Cash                     N             1           36  \n",
       "1                Cash                     N             1           36  \n",
       "2                Cash                     N             1           60  \n",
       "3                Cash                     N             1           60  \n",
       "4                Cash                     N             1           36  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_acc',\n",
       " 'loan_amnt',\n",
       " 'dti',\n",
       " 'revol_util',\n",
       " 'tax_liens',\n",
       " 'pub_rec',\n",
       " 'chargeoff_within_12_mths',\n",
       " 'total_rec_int',\n",
       " 'fico_range_high',\n",
       " 'annual_inc',\n",
       " 'open_acc',\n",
       " 'last_pymnt_amnt',\n",
       " 'delinq_2yrs',\n",
       " 'delinq_amnt',\n",
       " 'last_fico_range_high',\n",
       " 'recoveries',\n",
       " 'revol_bal',\n",
       " 'acc_now_delinq',\n",
       " 'term_months',\n",
       " 'int_rate',\n",
       " 'pub_rec_bankruptcies',\n",
       " 'total_rec_late_fee',\n",
       " 'inq_last_6mths',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'sub_grade_class_vec',\n",
       " 'verification_status_class_vec',\n",
       " 'application_type_class_vec',\n",
       " 'initial_list_status_class_vec',\n",
       " 'purpose_class_vec',\n",
       " 'home_ownership_class_vec',\n",
       " 'disbursement_method_class_vec',\n",
       " 'debt_settlement_flag_class_vec']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Pipeline\n",
    "cat_features = ['sub_grade', 'verification_status', 'application_type', 'initial_list_status', \n",
    "                'purpose', 'home_ownership', 'disbursement_method', 'debt_settlement_flag']\n",
    "assembler_inputs = list(set(df.columns) - set(cat_features)) + [feature + \"_class_vec\" for feature in cat_features]\n",
    "assembler_inputs.remove('loan_is_paid')\n",
    "assembler_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Stages List\n",
    "stages = []\n",
    "\n",
    "# Loop for StringIndexer and OHE for Categorical Variables\n",
    "for features in cat_features:\n",
    "    # Index Categorical Features\n",
    "    string_indexer = StringIndexer(inputCol=features, outputCol=features + \"_index\")\n",
    "    # One Hot Encode Categorical Features\n",
    "    encoder = OneHotEncoder(inputCols=[string_indexer.getOutputCol()], outputCols=[features + \"_class_vec\"])\n",
    "    # Append Pipeline Stages\n",
    "    stages += [string_indexer, encoder]\n",
    "    \n",
    "assembler_final = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\") \n",
    "\n",
    "stages += [assembler_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_746ac282e186,\n",
       " OneHotEncoder_fb5fe76b2cb1,\n",
       " StringIndexer_6ad93e3b29b0,\n",
       " OneHotEncoder_cc014fe82f92,\n",
       " StringIndexer_d919f21325a5,\n",
       " OneHotEncoder_b175e7e33995,\n",
       " StringIndexer_7ce1f840c1a8,\n",
       " OneHotEncoder_275334ab715b,\n",
       " StringIndexer_e701502d57df,\n",
       " OneHotEncoder_ef66d90c9edb,\n",
       " StringIndexer_e2e8ab6c3b3e,\n",
       " OneHotEncoder_fa56aa2e4a8f,\n",
       " StringIndexer_c243c9ddb932,\n",
       " OneHotEncoder_a2d7334a2a4a,\n",
       " StringIndexer_a3d96c225256,\n",
       " OneHotEncoder_37214ac0df2c,\n",
       " VectorAssembler_ee98ad8037d9]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pipeline\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Pipeline to Data\n",
    "pipeline_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Data using Fitted Pipeline\n",
    "df = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>...</th>\n",
       "      <th>initial_list_status_class_vec</th>\n",
       "      <th>purpose_index</th>\n",
       "      <th>purpose_class_vec</th>\n",
       "      <th>home_ownership_index</th>\n",
       "      <th>home_ownership_class_vec</th>\n",
       "      <th>disbursement_method_index</th>\n",
       "      <th>disbursement_method_class_vec</th>\n",
       "      <th>debt_settlement_flag_index</th>\n",
       "      <th>debt_settlement_flag_class_vec</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>13.99</td>\n",
       "      <td>C4</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>5.910000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(13.0, 3600.0, 5.909999847412109, 29.700000762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24700.0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>C1</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>small_business</td>\n",
       "      <td>16.059999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(38.0, 24700.0, 16.059999465942383, 19.2000007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>10.78</td>\n",
       "      <td>B4</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>10.780000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(18.0, 20000.0, 10.779999732971191, 56.2000007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10400.0</td>\n",
       "      <td>22.45</td>\n",
       "      <td>F1</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>104433.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>25.370001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(35.0, 10400.0, 25.3700008392334, 64.5, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11950.0</td>\n",
       "      <td>13.44</td>\n",
       "      <td>C3</td>\n",
       "      <td>RENT</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(6.0, 11950.0, 10.199999809265137, 68.40000152...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate sub_grade home_ownership  annual_inc  \\\n",
       "0     3600.0     13.99        C4       MORTGAGE     55000.0   \n",
       "1    24700.0     11.99        C1       MORTGAGE     65000.0   \n",
       "2    20000.0     10.78        B4       MORTGAGE     63000.0   \n",
       "3    10400.0     22.45        F1       MORTGAGE    104433.0   \n",
       "4    11950.0     13.44        C3           RENT     34000.0   \n",
       "\n",
       "  verification_status             purpose        dti  delinq_2yrs  \\\n",
       "0        Not Verified  debt_consolidation   5.910000          0.0   \n",
       "1        Not Verified      small_business  16.059999          1.0   \n",
       "2        Not Verified    home_improvement  10.780000          0.0   \n",
       "3     Source Verified      major_purchase  25.370001          1.0   \n",
       "4     Source Verified  debt_consolidation  10.200000          0.0   \n",
       "\n",
       "   fico_range_high  ...  initial_list_status_class_vec  purpose_index  \\\n",
       "0            679.0  ...                          (1.0)            0.0   \n",
       "1            719.0  ...                          (1.0)            6.0   \n",
       "2            699.0  ...                          (1.0)            2.0   \n",
       "3            699.0  ...                          (1.0)            4.0   \n",
       "4            694.0  ...                          (1.0)            0.0   \n",
       "\n",
       "                                   purpose_class_vec  home_ownership_index  \\\n",
       "0  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                   0.0   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...                   0.0   \n",
       "2  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                   0.0   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...                   0.0   \n",
       "4  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                   1.0   \n",
       "\n",
       "   home_ownership_class_vec  disbursement_method_index  \\\n",
       "0      (1.0, 0.0, 0.0, 0.0)                        0.0   \n",
       "1      (1.0, 0.0, 0.0, 0.0)                        0.0   \n",
       "2      (1.0, 0.0, 0.0, 0.0)                        0.0   \n",
       "3      (1.0, 0.0, 0.0, 0.0)                        0.0   \n",
       "4      (0.0, 1.0, 0.0, 0.0)                        0.0   \n",
       "\n",
       "  disbursement_method_class_vec  debt_settlement_flag_index  \\\n",
       "0                         (1.0)                         0.0   \n",
       "1                         (1.0)                         0.0   \n",
       "2                         (1.0)                         0.0   \n",
       "3                         (1.0)                         0.0   \n",
       "4                         (1.0)                         0.0   \n",
       "\n",
       "   debt_settlement_flag_class_vec  \\\n",
       "0                           (1.0)   \n",
       "1                           (1.0)   \n",
       "2                           (1.0)   \n",
       "3                           (1.0)   \n",
       "4                           (1.0)   \n",
       "\n",
       "                                            features  \n",
       "0  (13.0, 3600.0, 5.909999847412109, 29.700000762...  \n",
       "1  (38.0, 24700.0, 16.059999465942383, 19.2000007...  \n",
       "2  (18.0, 20000.0, 10.779999732971191, 56.2000007...  \n",
       "3  (35.0, 10400.0, 25.3700008392334, 64.5, 0.0, 0...  \n",
       "4  (6.0, 11950.0, 10.199999809265137, 68.40000152...  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Newly Transformed Data\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- dti: float (nullable = true)\n",
      " |-- delinq_2yrs: float (nullable = true)\n",
      " |-- fico_range_high: float (nullable = true)\n",
      " |-- inq_last_6mths: float (nullable = true)\n",
      " |-- open_acc: float (nullable = true)\n",
      " |-- pub_rec: float (nullable = true)\n",
      " |-- revol_bal: float (nullable = true)\n",
      " |-- revol_util: float (nullable = true)\n",
      " |-- total_acc: float (nullable = true)\n",
      " |-- initial_list_status: string (nullable = true)\n",
      " |-- total_rec_int: float (nullable = true)\n",
      " |-- total_rec_late_fee: float (nullable = true)\n",
      " |-- recoveries: float (nullable = true)\n",
      " |-- last_pymnt_amnt: float (nullable = true)\n",
      " |-- last_fico_range_high: float (nullable = true)\n",
      " |-- collections_12_mths_ex_med: float (nullable = true)\n",
      " |-- application_type: string (nullable = true)\n",
      " |-- acc_now_delinq: float (nullable = true)\n",
      " |-- chargeoff_within_12_mths: double (nullable = true)\n",
      " |-- delinq_amnt: double (nullable = true)\n",
      " |-- pub_rec_bankruptcies: double (nullable = true)\n",
      " |-- tax_liens: double (nullable = true)\n",
      " |-- disbursement_method: string (nullable = true)\n",
      " |-- debt_settlement_flag: string (nullable = true)\n",
      " |-- loan_is_paid: integer (nullable = true)\n",
      " |-- term_months: integer (nullable = true)\n",
      " |-- sub_grade_index: double (nullable = false)\n",
      " |-- sub_grade_class_vec: vector (nullable = true)\n",
      " |-- verification_status_index: double (nullable = false)\n",
      " |-- verification_status_class_vec: vector (nullable = true)\n",
      " |-- application_type_index: double (nullable = false)\n",
      " |-- application_type_class_vec: vector (nullable = true)\n",
      " |-- initial_list_status_index: double (nullable = false)\n",
      " |-- initial_list_status_class_vec: vector (nullable = true)\n",
      " |-- purpose_index: double (nullable = false)\n",
      " |-- purpose_class_vec: vector (nullable = true)\n",
      " |-- home_ownership_index: double (nullable = false)\n",
      " |-- home_ownership_class_vec: vector (nullable = true)\n",
      " |-- disbursement_method_index: double (nullable = false)\n",
      " |-- disbursement_method_class_vec: vector (nullable = true)\n",
      " |-- debt_settlement_flag_index: double (nullable = false)\n",
      " |-- debt_settlement_flag_class_vec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>loan_is_paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(13.0, 3600.0, 5.909999847412109, 29.700000762...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(38.0, 24700.0, 16.059999465942383, 19.2000007...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(18.0, 20000.0, 10.779999732971191, 56.2000007...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(35.0, 10400.0, 25.3700008392334, 64.5, 0.0, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(6.0, 11950.0, 10.199999809265137, 68.40000152...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(27.0, 20000.0, 14.670000076293945, 84.5, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(15.0, 20000.0, 17.610000610351562, 5.69999980...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(23.0, 10000.0, 13.069999694824219, 34.5, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(18.0, 8000.0, 34.79999923706055, 39.099998474...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(24.0, 1400.0, 34.95000076293945, 67.199996948...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(27.0, 18000.0, 9.390000343322754, 40.70000076...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(24.0, 28000.0, 21.600000381469727, 64.5, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(9.0, 9600.0, 22.440000534057617, 59.400001525...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(19.0, 25000.0, 26.020000457763672, 54.2999992...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(27.0, 18000.0, 8.680000305175781, 15.5, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(19.0, 8650.0, 25.489999771118164, 46.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(31.0, 29900.0, 21.770000457763672, 46.7000007...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(19.0, 16000.0, 33.18000030517578, 29.60000038...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(22.0, 28000.0, 7.489999771118164, 63.09999847...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(5.0, 5000.0, 12.699999809265137, 101.5, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  loan_is_paid\n",
       "0   (13.0, 3600.0, 5.909999847412109, 29.700000762...             1\n",
       "1   (38.0, 24700.0, 16.059999465942383, 19.2000007...             1\n",
       "2   (18.0, 20000.0, 10.779999732971191, 56.2000007...             1\n",
       "3   (35.0, 10400.0, 25.3700008392334, 64.5, 0.0, 0...             1\n",
       "4   (6.0, 11950.0, 10.199999809265137, 68.40000152...             1\n",
       "5   (27.0, 20000.0, 14.670000076293945, 84.5, 0.0,...             1\n",
       "6   (15.0, 20000.0, 17.610000610351562, 5.69999980...             1\n",
       "7   (23.0, 10000.0, 13.069999694824219, 34.5, 0.0,...             1\n",
       "8   (18.0, 8000.0, 34.79999923706055, 39.099998474...             1\n",
       "9   (24.0, 1400.0, 34.95000076293945, 67.199996948...             1\n",
       "10  (27.0, 18000.0, 9.390000343322754, 40.70000076...             0\n",
       "11  (24.0, 28000.0, 21.600000381469727, 64.5, 0.0,...             1\n",
       "12  (9.0, 9600.0, 22.440000534057617, 59.400001525...             1\n",
       "13  (19.0, 25000.0, 26.020000457763672, 54.2999992...             1\n",
       "14  (27.0, 18000.0, 8.680000305175781, 15.5, 0.0, ...             1\n",
       "15  (19.0, 8650.0, 25.489999771118164, 46.0, 0.0, ...             1\n",
       "16  (31.0, 29900.0, 21.770000457763672, 46.7000007...             1\n",
       "17  (19.0, 16000.0, 33.18000030517578, 29.60000038...             1\n",
       "18  (22.0, 28000.0, 7.489999771118164, 63.09999847...             1\n",
       "19  (5.0, 5000.0, 12.699999809265137, 101.5, 0.0, ...             1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.select('features','loan_is_paid')\n",
    "df.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle Data\n",
    "df = df.orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Train / Test Sets\n",
    "train_data, test_data = df.randomSplit([.8, .2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340812, 2)\n"
     ]
    }
   ],
   "source": [
    "print(spark_df_shape(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Inputs or Input Dimensions\n",
    "input_dim = len(train_data.select(\"features\").first()[0])\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1073352, 2)\n"
     ]
    }
   ],
   "source": [
    "print(spark_df_shape(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(267460, 2)\n"
     ]
    }
   ],
   "source": [
    "print(spark_df_shape(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     # Set up Deep Learning Model / Architecture\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=78, input_shape=(input_dim,), activation='relu'))\n",
    "#     model.add(Dense(units=39,activation='relu'))\n",
    "#     model.add(Dense(units=19,activation='relu'))\n",
    "#     model.add(Dense(units=8,activation='relu'))\n",
    "#     model.add(Dense(units=4,activation='relu'))\n",
    "#     model.add(Dense(units=2,activation='softmax'))\n",
    "#     return model\n",
    "\n",
    "# def compile_model(model):\n",
    "#     model.compile(loss='categorical_crossentrop', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "def create_model():\n",
    "    # Set up Deep Learning Model / Architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=78, input_shape=(input_dim,), activation='relu'))\n",
    "    model.add(Dense(units=39,activation='relu'))\n",
    "    model.add(Dense(units=19,activation='relu'))\n",
    "    model.add(Dense(units=8,activation='relu'))\n",
    "    model.add(Dense(units=4,activation='relu'))\n",
    "    model.add(Dense(units=1,activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(loss='binary_crossentrop', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 78)                6396      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 39)                3081      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 19)                760       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 8)                 160       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 10,438\n",
      "Trainable params: 10,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model = compile_model(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_is_paid</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>860598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>212754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_is_paid   count\n",
       "0             1  860598\n",
       "1             0  212754"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupBy(\"loan_is_paid\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_is_paid</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>214363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>53097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_is_paid   count\n",
       "0             1  214363\n",
       "1             0   53097"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.groupBy(\"loan_is_paid\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElephasEstimator_6638f9879e70"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.01)\n",
    "opt_conf = optimizers.serialize(adam)\n",
    "\n",
    "# Initialize SparkML Estimator and set all relevant properties\n",
    "estimator = ElephasEstimator()\n",
    "estimator.setFeaturesCol(\"features\")\n",
    "estimator.setLabelCol(\"loan_is_paid\")\n",
    "estimator.set_keras_model_config(model.to_yaml()) # Provide serialized Keras model\n",
    "estimator.set_num_workers(1)                      # We just use one worker here. Feel free to adapt it.\n",
    "estimator.set_epochs(10)\n",
    "estimator.set_batch_size(512)\n",
    "estimator.set_verbosity(1)\n",
    "estimator.set_validation_split(0.1)\n",
    "estimator.set_categorical_labels(True)\n",
    "estimator.set_nb_classes(2)\n",
    "estimator.set_optimizer_config(opt_conf)\n",
    "estimator.set_mode(\"asynchronous\")\n",
    "# estimator.set_loss(\"categorical_crossentrop\")\n",
    "estimator.set_loss(\"binary_crossentrop\")\n",
    "estimator.set_metrics(['accuracy'])\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "\n",
    "# from elephas.spark_model import SparkModel\n",
    "\n",
    "# spark_model = SparkModel(model, frequency='epoch', mode='asynchronous')\n",
    "# spark_model.fit(rdd, epochs=5, batch_size=512, verbose=1, validation_split=0.1)\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "# epochs = 40\n",
    "# batch_size = 512\n",
    "# nb_classes = 2\n",
    "# estimator = ElephasEstimator(epochs=epochs, batch_size=batch_size, frequency='batch', mode='asynchronous', categorical=True, nb_classes=nb_classes)\n",
    "# # estimator = ElephasEstimator(epochs=epochs, batch_size=batch_size, frequency='batch', mode='asynchronous', categorical=True)\n",
    "\n",
    "# estimator.setFeaturesCol(\"features\")\n",
    "# estimator.setLabelCol(\"loan_is_paid\")\n",
    "# estimator.set_keras_model_config(model.to_yaml())\n",
    "# estimator.set_verbosity(1)\n",
    "# estimator.set_validation_split(0.1)\n",
    "# adam = optimizers.Adam(lr=0.01)\n",
    "# opt_conf = optimizers.serialize(adam)\n",
    "\n",
    "# estimator.set_loss(\"categorical_crossentrop\")\n",
    "# estimator.set_metrics(['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- loan_is_paid: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- loan_is_paid: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_pipeline = Pipeline(stages=[estimator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Fit model\n",
      ">>> Initialize workers\n",
      ">>> Distribute load\n",
      " * Serving Flask app \"elephas.parameter.server\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/elephas/parameter/server.py\", line 136, in start_flask_service\n",
      "    threaded=self.threaded, use_reloader=self.use_reloader)\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/flask/app.py\", line 990, in run\n",
      "    run_simple(host, port, self, **options)\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/werkzeug/serving.py\", line 1052, in run_simple\n",
      "    inner()\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/werkzeug/serving.py\", line 1005, in inner\n",
      "    fd=fd,\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/werkzeug/serving.py\", line 863, in make_server\n",
      "    host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/werkzeug/serving.py\", line 740, in __init__\n",
      "    HTTPServer.__init__(self, server_address, handler)\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/socketserver.py\", line 452, in __init__\n",
      "    self.server_bind()\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/http/server.py\", line 137, in server_bind\n",
      "    socketserver.TCPServer.server_bind(self)\n",
      "  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/socketserver.py\", line 466, in server_bind\n",
      "    self.socket.bind(self.server_address)\n",
      "OSError: [Errno 98] Address already in use\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 98.0 failed 1 times, most recent failure: Lost task 0.0 in stage 98.0 (TID 2289) (192.168.1.5 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/elephas/worker.py\", line 105, in train\n    self.model.set_weights(weights_before_training)\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1873, in set_weights\n    'shape %s' % (ref_shape, weight.shape))\nValueError: Layer weight shape (4, 1) not compatible with provided weight shape (4, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2267)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/elephas/worker.py\", line 105, in train\n    self.model.set_weights(weights_before_training)\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1873, in set_weights\n    'shape %s' % (ref_shape, weight.shape))\nValueError: Layer weight shape (4, 1) not compatible with provided weight shape (4, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-891a786697a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_dl_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/elephas/ml_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     96\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                         validation_split=self.get_validation_split())\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mmodel_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, rdd, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'asynchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'synchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hogwild'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, rdd, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 yaml, parameters, self.client, train_config, freq, optimizer, loss, metrics, custom)\n\u001b[1;32m    174\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>> Distribute load'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>> Async training complete.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mnew_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \"\"\"\n\u001b[1;32m    948\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bigdata/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 98.0 failed 1 times, most recent failure: Lost task 0.0 in stage 98.0 (TID 2289) (192.168.1.5 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/elephas/worker.py\", line 105, in train\n    self.model.set_weights(weights_before_training)\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1873, in set_weights\n    'shape %s' % (ref_shape, weight.shape))\nValueError: Layer weight shape (4, 1) not compatible with provided weight shape (4, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2267)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/elephas/worker.py\", line 105, in train\n    self.model.set_weights(weights_before_training)\n  File \"/home/abdulrahman/anaconda3/envs/bigdata/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1873, in set_weights\n    'shape %s' % (ref_shape, weight.shape))\nValueError: Layer weight shape (4, 1) not compatible with provided weight shape (4, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "fit_dl_pipeline = dl_pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test = fit_dl_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_test = pred_test.select(\"loan_is_paid\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_label_test = pnl_test.rdd.map(lambda row: (row[\"loan_is_paid\"], row['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_test = MulticlassMetrics(pred_and_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTest Data Accuracy: {}\".format(metrics_test.weightedPrecision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Data Confusion Matrix\")\n",
    "display(pnl_test.crosstab('loan_is_paid', 'prediction').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
